"""
æ–‡æ¡£é¢„å¤„ç†æœåŠ¡
ç»Ÿä¸€çš„æ–‡æ¡£è§£æå…¥å£
"""

import uuid
import time
from typing import Union, Optional, Dict, Any
from pathlib import Path

from .pdf_parser import PDFParser
from .docx_parser import DOCXParser
from ..services.ocr_service import OCRService
from ..models.document_models import DocumentParseResult, DocumentType, TextBlock
from ..utils.logger import get_document_logger


logger = get_document_logger('processor')


class DocumentProcessor:
    """æ–‡æ¡£é¢„å¤„ç†å™¨ä¸»ç±»"""
    
    def __init__(self, enable_ocr: bool = True, ocr_lang: str = 'ch'):
        """
        åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨
        
        Args:
            enable_ocr: æ˜¯å¦å¯ç”¨OCRåŠŸèƒ½
            ocr_lang: OCRè¯­è¨€è®¾ç½®
        """
        self.pdf_parser = PDFParser()
        self.docx_parser = DOCXParser()
        
        # åˆå§‹åŒ–OCRæœåŠ¡
        self.ocr_service = None
        if enable_ocr:
            try:
                self.ocr_service = OCRService(lang=ocr_lang)
                self.pdf_parser.set_ocr_service(self.ocr_service)
                logger.info("OCRæœåŠ¡å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"OCRæœåŠ¡åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ç¦ç”¨OCRåŠŸèƒ½: {e}")
    
    def process_file(self, file_path: str, document_id: Optional[str] = None) -> DocumentParseResult:
        """
        å¤„ç†æ–‡æ¡£æ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            document_id: æ–‡æ¡£ID
            
        Returns:
            DocumentParseResult: è§£æç»“æœ
        """
        if document_id is None:
            document_id = str(uuid.uuid4())
            
        file_path_obj = Path(file_path)
        if not file_path_obj.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        file_extension = file_path_obj.suffix.lower()
        file_size = file_path_obj.stat().st_size
        
        logger.info(f"ğŸ” å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path_obj.name} ({file_extension}, {file_size} å­—èŠ‚)")
        start_time = time.time()
        
        try:
            if file_extension == '.pdf':
                logger.debug("ğŸ“„ ä½¿ç”¨PDFè§£æå™¨")
                result = self.pdf_parser.parse(file_path, document_id)
            elif file_extension == '.docx':
                logger.debug("ğŸ“ ä½¿ç”¨DOCXè§£æå™¨")
                result = self.docx_parser.parse(file_path, document_id)
            elif file_extension in ['.txt', '.md']:
                logger.debug("ğŸ“ƒ ä½¿ç”¨æ–‡æœ¬è§£æå™¨")
                result = self._parse_text_file(file_path, document_id)
            elif file_extension == '.json':
                logger.debug("ğŸ“‹ ä½¿ç”¨JSONè§£æå™¨")
                result = self._parse_json_file(file_path, document_id)
            else:
                supported = list(self.get_supported_formats().keys())
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_extension}. æ”¯æŒçš„æ ¼å¼: {supported}")
            
            processing_time = time.time() - start_time
            logger.info(f"âœ… æ–‡ä»¶å¤„ç†å®Œæˆ: {file_path_obj.name}, è€—æ—¶: {processing_time:.2f}ç§’, "
                       f"é¡µæ•°: {result.total_pages}, æ–‡æœ¬å—: {len(result.all_text_blocks)}ä¸ª, "
                       f"æ–‡æœ¬é•¿åº¦: {result.total_text_length}å­—ç¬¦")
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {file_path_obj.name}, è€—æ—¶: {processing_time:.2f}ç§’, é”™è¯¯: {e}")
            raise
    
    def _parse_text_file(self, file_path: str, document_id: str) -> DocumentParseResult:
        """è§£æçº¯æ–‡æœ¬æ–‡ä»¶"""
        import time
        start_time = time.time()
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = content.split('\n\n')
        
        text_blocks = []
        char_offset = 0
        
        for i, paragraph in enumerate(paragraphs):
            if paragraph.strip():
                block_id = f"{document_id}_para{i}"
                
                block = TextBlock(
                    text=paragraph.strip(),
                    page_number=1,
                    block_id=block_id,
                    char_start=char_offset,
                    char_end=char_offset + len(paragraph),
                    confidence=1.0,
                    is_ocr=False
                )
                
                text_blocks.append(block)
                char_offset += len(paragraph)
        
        from ..models.document_models import PageInfo
        
        page_info = PageInfo(
            page_number=1,
            width=595,
            height=842,
            text_blocks=text_blocks
        )
        
        processing_time = time.time() - start_time
        
        return DocumentParseResult(
            document_id=document_id,
            document_type=DocumentType.TXT,
            total_pages=1,
            total_text_length=len(content),
            pages=[page_info],
            all_text_blocks=text_blocks,
            metadata={
                "file_path": file_path,
                "file_size": Path(file_path).stat().st_size,
                "parser": "text"
            },
            processing_time=processing_time
        )
    
    def _parse_json_file(self, file_path: str, document_id: str) -> DocumentParseResult:
        """è§£æJSONæ–‡ä»¶"""
        import json
        import time
        start_time = time.time()
        
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # å°†JSONå†…å®¹è½¬æ¢ä¸ºæ–‡æœ¬
        content = json.dumps(data, ensure_ascii=False, indent=2)
        
        # åˆ›å»ºå•ä¸ªæ–‡æœ¬å—
        block = TextBlock(
            text=content,
            page_number=1,
            block_id=f"{document_id}_json",
            char_start=0,
            char_end=len(content),
            confidence=1.0,
            is_ocr=False
        )
        
        from ..models.document_models import PageInfo
        
        page_info = PageInfo(
            page_number=1,
            width=595,
            height=842,
            text_blocks=[block]
        )
        
        processing_time = time.time() - start_time
        
        return DocumentParseResult(
            document_id=document_id,
            document_type=DocumentType.JSON,
            total_pages=1,
            total_text_length=len(content),
            pages=[page_info],
            all_text_blocks=[block],
            metadata={
                "file_path": file_path,
                "file_size": Path(file_path).stat().st_size,
                "parser": "json"
            },
            processing_time=processing_time
        )
    
    def process_image_with_ocr(self, image_path: Union[str, Path], document_id: Optional[str] = None) -> DocumentParseResult:
        """
        ä½¿ç”¨OCRå¤„ç†å›¾ç‰‡æ–‡ä»¶
        
        Args:
            image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            document_id: æ–‡æ¡£ID
            
        Returns:
            DocumentParseResult: è§£æç»“æœ
        """
        if not self.ocr_service:
            raise RuntimeError("OCRæœåŠ¡æœªå¯ç”¨")
        
        if document_id is None:
            document_id = str(uuid.uuid4())
        
        image_path = Path(image_path)
        logger.info(f"å¼€å§‹OCRè¯†åˆ«å›¾ç‰‡: {image_path}")
        
        import time
        start_time = time.time()
        
        # æ‰§è¡ŒOCRè¯†åˆ«
        ocr_results = self.ocr_service.recognize_image(image_path)
        
        # è½¬æ¢ä¸ºTextBlock
        text_blocks = []
        total_text = ""
        
        for i, ocr_result in enumerate(ocr_results):
            block = TextBlock(
                text=ocr_result.text,
                page_number=1,
                block_id=f"{document_id}_ocr{i}",
                original_position=ocr_result.bbox,
                char_start=len(total_text),
                char_end=len(total_text) + len(ocr_result.text),
                confidence=ocr_result.confidence,
                is_ocr=True
            )
            
            text_blocks.append(block)
            total_text += ocr_result.text + "\n"
        
        from ..models.document_models import PageInfo
        
        page_info = PageInfo(
            page_number=1,
            width=800,  # é»˜è®¤å›¾ç‰‡å®½åº¦
            height=600, # é»˜è®¤å›¾ç‰‡é«˜åº¦
            text_blocks=text_blocks,
            has_images=True,
            image_count=1
        )
        
        processing_time = time.time() - start_time
        
        return DocumentParseResult(
            document_id=document_id,
            document_type=DocumentType.PDF,  # å›¾ç‰‡å½“ä½œPDFå¤„ç†
            total_pages=1,
            total_text_length=len(total_text),
            pages=[page_info],
            all_text_blocks=text_blocks,
            metadata={
                "file_path": str(image_path),
                "file_size": image_path.stat().st_size,
                "parser": "ocr",
                "ocr_blocks": len(ocr_results)
            },
            processing_time=processing_time
        )
    
    @staticmethod
    def get_supported_formats() -> Dict[str, str]:
        """è·å–æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"""
        return {
            '.pdf': 'PDFæ–‡æ¡£',
            '.docx': 'Wordæ–‡æ¡£',
            '.txt': 'çº¯æ–‡æœ¬æ–‡ä»¶',
            '.md': 'Markdownæ–‡ä»¶',
            '.json': 'JSONæ–‡ä»¶',
            '.png': 'å›¾ç‰‡æ–‡ä»¶ï¼ˆéœ€OCRï¼‰',
            '.jpg': 'å›¾ç‰‡æ–‡ä»¶ï¼ˆéœ€OCRï¼‰',
            '.jpeg': 'å›¾ç‰‡æ–‡ä»¶ï¼ˆéœ€OCRï¼‰'
        }
    
    def is_ocr_enabled(self) -> bool:
        """æ£€æŸ¥OCRæ˜¯å¦å¯ç”¨"""
        return self.ocr_service is not None and self.ocr_service.is_available()